{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from pprint import pprint\n",
    "from inspect import getmembers\n",
    "from gurobipy import *\n",
    "import numpy as np\n",
    "import random as random\n",
    "import math\n",
    "import copy\n",
    "import timeit\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "'''\n",
    "recursive function that returns the binary path: 0 for left, 1 for right to all leaves in a dictionary\n",
    "-input: treenode= starting node (0)\n",
    "        binary_path= initialised with -1's\n",
    "-output: a dictionary with a key for each leaf, and an array (length=num_nodes in tree) with 0 for left, 1 for right at each split, -1 if split doesn't arrive at leaf\n",
    "'''\n",
    "def get_binary_path_to_leaf(binary_path,tree,node):\n",
    "\n",
    "    # go to next node if not leaf\n",
    "    if tree.children_left[node]>0:\n",
    "        binary_path_left=np.copy(binary_path)\n",
    "        binary_path_left[node]=0\n",
    "        binary_path_right=np.copy(binary_path)\n",
    "        binary_path_right[node]=1\n",
    "        child_list_left=get_binary_path_to_leaf(binary_path_left,tree,tree.children_left[node])\n",
    "        child_list_right=get_binary_path_to_leaf(binary_path_right,tree,tree.children_right[node])\n",
    "    else:\n",
    "        # pass back dictionary\n",
    "        return {node:binary_path}\n",
    "\n",
    "    #combine dictionaries\n",
    "    dall = {}\n",
    "    dall.update(child_list_left)\n",
    "    dall.update(child_list_right)\n",
    "    #print(\"dall\",dall)\n",
    "    return dall\n",
    "\n",
    "\n",
    "'''\n",
    "Returns the depth of each node in the tree\n",
    "-input: tree object\n",
    "-output: (n_node array) an array with the depth of each node at the index of the node\n",
    "'''\n",
    "def get_depth(tree):\n",
    "\n",
    "    num_nodes=tree.node_count\n",
    "    depth_node=np.zeros([num_nodes])\n",
    "    current_nodes=[0]\n",
    "    current_depth=0\n",
    "    new_nodes=[]\n",
    "    while current_nodes:\n",
    "        for node in current_nodes:\n",
    "\n",
    "            if not(tree.children_left[node] == -1):\n",
    "                new_nodes.append(tree.children_left[node])\n",
    "\n",
    "            if not(tree.children_right[node] == -1):\n",
    "                new_nodes.append(tree.children_right[node])\n",
    "\n",
    "            depth_node[node]=current_depth\n",
    "\n",
    "        current_nodes=new_nodes\n",
    "        new_nodes=[]\n",
    "        current_depth+=1\n",
    "\n",
    "    return depth_node\n",
    "\n",
    "'''\n",
    "truncate tree to a certain depth\n",
    "'''\n",
    "\n",
    "def truncate_to_given_depth(forest,max_depth):\n",
    "\n",
    "    estimators=forest.estimators_\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "        tree=tree_in_forest.tree_\n",
    "        depth=get_depth(tree)\n",
    "        num_nodes=tree.node_count\n",
    "\n",
    "        for node in range(num_nodes):\n",
    "            if depth[node]>=max_depth:\n",
    "                tree.children_left[node]=-1\n",
    "                tree.children_right[node]=-1\n",
    "\n",
    "    return forest\n",
    "\n",
    "\n",
    "'''\n",
    "Returns a a list of indices corresponding to the leaves of a tree\n",
    "'''\n",
    "def get_leaf_indices(tree):\n",
    "\n",
    "    current_nodes=[0]\n",
    "    leaf_indicies=[]\n",
    "    new_nodes=[]\n",
    "    while current_nodes:\n",
    "        for node in current_nodes:\n",
    "\n",
    "            if not(tree.children_left[node] == -1):\n",
    "                new_nodes.append(tree.children_left[node])\n",
    "            else: leaf_indicies.append(node)\n",
    "\n",
    "            if not(tree.children_right[node] == -1):\n",
    "                new_nodes.append(tree.children_right[node])\n",
    "\n",
    "        current_nodes=new_nodes\n",
    "        new_nodes=[]\n",
    "\n",
    "    return leaf_indicies\n",
    "\n",
    "'''\n",
    "Input - sklearn random forest\n",
    "Output - splits: (num_featres x num_splits per feature) ordered list with threshold defining splits in all trees\n",
    "'''\n",
    "def get_ordered_thresholds_for_each_feature(forest, num_features):\n",
    "    splits = []\n",
    "    for feat in range(num_features):\n",
    "        splits.append([])\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(forest):\n",
    "        tree=tree_in_forest.tree_\n",
    "        index_splits=np.where(tree.children_left!= (-1))[0]\n",
    "\n",
    "        for i in index_splits:\n",
    "            var_split=tree.feature[i]\n",
    "            splits[var_split].append(tree.threshold[i])\n",
    "\n",
    "    for feat in range(num_features):\n",
    "        splits[feat].sort()\n",
    "\n",
    "    return splits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_dataset(dataset,n_data,n_feature):\n",
    "\n",
    "    if dataset == 'wine':\n",
    "        # n_trees_train=10\n",
    "        x = pd.read_csv('winequality.csv', sep=',')\n",
    "        wine_headings = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides',\n",
    "                         'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "        y = x[[\"quality\"]]\n",
    "        del x['quality']\n",
    "\n",
    "        feature_upper_bounds = [15.9, 1.58, 1, 15.5, 0.611, 72, 289, 1.00369, 4.01, 2, 14.9]\n",
    "        feature_lower_bounds = [4.6, 0.12, 0, 0.9, 0.012, 1, 6, 0.99007, 2.74, 0.33, 8.4]\n",
    "\n",
    "        n_feature=len(wine_headings)\n",
    "        n_data=len(y)\n",
    "        \n",
    "\n",
    "    if dataset == 'concrete':\n",
    "        # n_trees_train=10\n",
    "        x = pd.read_csv('concrete.csv', sep=',')\n",
    "        y = x[[\"CompressiveStrength\"]]\n",
    "        del x['CompressiveStrength']\n",
    "\n",
    "        feature_upper_bounds = [540,359.4,200.1,247,32.2,1145,992.6,365,82.6]\n",
    "        feature_lower_bounds = [102,0,0,121.8,0,801,594,1,2.33]\n",
    "\n",
    "        n_feature=x.shape[1]\n",
    "        n_data=x.shape[0]\n",
    "        \n",
    "    if dataset == 'linear_synth':\n",
    "\n",
    "        n_data = 5000\n",
    "        n_feature = 10\n",
    "\n",
    "        feature_upper_bounds=[5]*n_feature\n",
    "        feature_lower_bounds=[-5]*n_feature\n",
    "\n",
    "        x=np.random.randint(10,  size=(n_data,n_feature))-5\n",
    "\n",
    "        # a simple linear model (still hard to learn for a tree)\n",
    "        beta=np.random.rand(n_feature)\n",
    "        y=x.dot(beta)\n",
    "        \n",
    "    if dataset == 'abs_synth':\n",
    "\n",
    "        feature_upper_bounds=[2]*n_feature\n",
    "        feature_lower_bounds=[0]*n_feature\n",
    "\n",
    "        x=np.random.rand(n_data,n_feature)*2\n",
    "        y=np.sum(1-np.abs(x-1),1)\n",
    "        \n",
    "    if dataset == 'abs_synth_noisy':\n",
    "\n",
    "        feature_upper_bounds=[2]*n_feature\n",
    "        feature_lower_bounds=[0]*n_feature\n",
    "\n",
    "        x=np.random.rand(n_data,n_feature)*2\n",
    "        y=np.sum(1-np.abs(x-1),1) + np.random.rand(n_data)*n_feature\n",
    "#         y=np.sum(1-np.abs(x-1),1) + np.random.normal(0,1,n_data)\n",
    "\n",
    "        \n",
    "        \n",
    "    return x,y,feature_upper_bounds,feature_lower_bounds,n_data,n_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_indices_recursive(tree, curr_index):\n",
    "    if tree.children_left[curr_index] > -1:\n",
    "        leaves_a=get_leaf_indices_recursive(tree,tree.children_left[curr_index])\n",
    "        leaves_b=get_leaf_indices_recursive(tree,tree.children_right[curr_index])\n",
    "        return leaves_a | leaves_b \n",
    "    else:\n",
    "        return {curr_index}\n",
    "\n",
    "def add_deviation_bound(m,feature_var,x,num_total_features):\n",
    "\n",
    "    mean_x=x.mean()\n",
    "    sd_x=np.sqrt(x.var())\n",
    "    norm_dev={}\n",
    "    for feat in range(num_total_features):\n",
    "        norm_dev[feat]=m.addVar(lb=-GRB.INFINITY,name=\"norm_dev\"+str(feat))\n",
    "        if  type(x.mean())==pd.core.series.Series:\n",
    "            m.addConstr(norm_dev[feat] >= (feature_var[feat]- mean_x[feat])/ sd_x[feat])\n",
    "            m.addConstr(norm_dev[feat] >= (-feature_var[feat] + mean_x[feat])/ sd_x[feat])\n",
    "        else:\n",
    "            m.addConstr(norm_dev[feat] >= (feature_var[feat]- mean_x)/ sd_x)\n",
    "            m.addConstr(norm_dev[feat] >= (-feature_var[feat] + mean_x)/ sd_x)\n",
    "\n",
    "    m.addConstr(quicksum(norm_dev[feat] for feat in range(num_total_features)) <= 0.1*num_total_features)\n",
    "                   \n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # misic formulation\n",
    "def misic_opt(estimators,num_total_features,feature_upper_bounds,feature_lower_bounds,x,eps,make_continuous,deviation_bound,make_relax):\n",
    "\n",
    "    m = Model(\"RF\")\n",
    "    m.setParam('TimeLimit', 1800)\n",
    "#     m.setParam('TimeLimit', 60)\n",
    "\n",
    "    num_trees=len(estimators)\n",
    "    in_leaf_var={}\n",
    "    split_var={}\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "        tree=tree_in_forest.tree_\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "\n",
    "        for leaf in index_leaves:\n",
    "            in_leaf_var[leaf,tree_index]=m.addVar(vtype=GRB.BINARY,name=\"in_leaf_var\"+str(leaf)+\"tree_index\"+str(tree_index))\n",
    "\n",
    "        m.addConstr(quicksum(in_leaf_var[leaf,tree_index] for leaf in index_leaves)==1)\n",
    "\n",
    "    for feat in range(n_feature):\n",
    "        feat_indices_all=[]\n",
    "        tree_indices_all=[]\n",
    "        feat_thresholds_all=[]\n",
    "\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "            tree=tree_in_forest.tree_\n",
    "            feat_indices=np.where(tree.feature==feat)[0]\n",
    "            feat_thresholds=tree.threshold[tree.feature==feat]\n",
    "            order_indices=np.argsort(feat_thresholds)\n",
    "\n",
    "            leaf_indices=set()\n",
    "\n",
    "            for i in range(len(feat_indices)):\n",
    "                split_var[feat,feat_indices[order_indices][i],tree_index]=m.addVar(vtype=GRB.BINARY,name=\"split_var\"+str(feat)+\"-\"+str(feat_indices[order_indices][i])+\"_tree\"+str(tree_index))\n",
    "\n",
    "                new_leaf_indices=get_leaf_indices_recursive(tree,tree.children_left[feat_indices[order_indices][i]])\n",
    "                right_leaf_indices=get_leaf_indices_recursive(tree,tree.children_right[feat_indices[order_indices][i]])\n",
    "\n",
    "\n",
    "                leaf_indices= new_leaf_indices | leaf_indices\n",
    "                m.addConstr(split_var[feat,feat_indices[order_indices][i],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in new_leaf_indices))\n",
    "                m.addConstr(1 - split_var[feat,feat_indices[order_indices][i],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in right_leaf_indices))\n",
    "\n",
    "            feat_indices_all=np.append(feat_indices_all,feat_indices)\n",
    "            feat_thresholds_all=np.append(feat_thresholds_all,feat_thresholds)\n",
    "            tree_indices_all=np.append(tree_indices_all,np.ones(len(feat_indices))*tree_index)\n",
    "\n",
    "        indices_to_sort=np.argsort(feat_thresholds_all)\n",
    "        ordered_thresholds=feat_thresholds_all[indices_to_sort]\n",
    "        ordered_tree_indices=tree_indices_all[indices_to_sort]\n",
    "        ordered_indices=feat_indices_all[indices_to_sort]\n",
    "\n",
    "        for i in range(len(indices_to_sort)-1):\n",
    "            m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       <= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "            if ordered_thresholds[i]==ordered_thresholds[i+1]:\n",
    "                m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       >= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "\n",
    "\n",
    "    # Summing objective over all trees\n",
    "    m.setObjective(quicksum(quicksum(in_leaf_var[leaf,tree_index]*tree_in_forest.tree_.value[leaf,0,0] \n",
    "                                     for leaf in np.array(get_leaf_indices(tree_in_forest.tree_))) for tree_index,tree_in_forest in enumerate(estimators))/float(num_trees),GRB.MAXIMIZE)\n",
    "\n",
    "    m.write(\"new_model_file.lp\")\n",
    "    \n",
    "    leaf_out=np.ones([num_trees])\n",
    "    if make_relax==True:\n",
    "        relax = m.relax()\n",
    "        relax.optimize()\n",
    "        obj = relax.getObjective()\n",
    "    else:\n",
    "        m.optimize()\n",
    "        obj = m.getObjective()\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "            tree=tree_in_forest.tree_\n",
    "            index_leaves=np.array(get_leaf_indices(tree))\n",
    "            for i in index_leaves:\n",
    "                if m.getVarByName(\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index)).x==1:\n",
    "                    leaf_out[tree_index]=i\n",
    "\n",
    "    return obj.getValue(),leaf_out, m.Runtime\n",
    "\n",
    "\n",
    "\n",
    "# expset formulation\n",
    "def misic_opt_tighter(estimators,num_total_features,feature_upper_bounds,feature_lower_bounds,x,eps,make_continuous,deviation_bound,make_relax):\n",
    "\n",
    "    m = Model(\"RF both ways greater and less than\")\n",
    "    m.setParam('TimeLimit', 1800)\n",
    "#     m.setParam('TimeLimit', 60)\n",
    "    num_trees=len(estimators)\n",
    "    in_leaf_var={}\n",
    "    split_var={}\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "        tree=tree_in_forest.tree_\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "\n",
    "        for leaf in index_leaves:\n",
    "            in_leaf_var[leaf,tree_index]=m.addVar(vtype=GRB.BINARY,name=\"in_leaf_var\"+str(leaf)+\"tree_index\"+str(tree_index))\n",
    "\n",
    "        m.addConstr(quicksum(in_leaf_var[leaf,tree_index] for leaf in index_leaves)==1)\n",
    "\n",
    "    for feat in range(n_feature):\n",
    "\n",
    "        print('feat',feat)\n",
    "\n",
    "        feat_indices_all=[]\n",
    "        tree_indices_all=[]\n",
    "        feat_thresholds_all=[]\n",
    "\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "            print('tree_index',tree_index)\n",
    "\n",
    "            tree=tree_in_forest.tree_\n",
    "            feat_indices=np.where(tree.feature==feat)[0]\n",
    "            feat_thresholds=tree.threshold[tree.feature==feat]\n",
    "            order_indices=np.argsort(feat_thresholds)\n",
    "\n",
    "            leaf_indices=set()\n",
    "            n_ind=len(feat_indices)\n",
    "\n",
    "            for i in range(n_ind):\n",
    "                split_var[feat,feat_indices[order_indices][i],tree_index]=m.addVar(vtype=GRB.BINARY,name=\"split_var\"+str(feat)+\"-\"+str(feat_indices[order_indices][i])+\"_tree\"+str(tree_index))\n",
    "                new_leaf_indices=get_leaf_indices_recursive(tree,tree.children_left[feat_indices[order_indices][i]])\n",
    "                leaf_indices= new_leaf_indices | leaf_indices\n",
    "                m.addConstr(split_var[feat,feat_indices[order_indices][i],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in leaf_indices))\n",
    "\n",
    "            larger_leaf_indices=set()\n",
    "\n",
    "            for i in range(n_ind):\n",
    "                right_leaf_indices=get_leaf_indices_recursive(tree,tree.children_right[feat_indices[order_indices][n_ind-i-1]])\n",
    "                larger_leaf_indices= right_leaf_indices | larger_leaf_indices\n",
    "                m.addConstr(1 - split_var[feat,feat_indices[order_indices][n_ind-i-1],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in larger_leaf_indices))\n",
    "\n",
    "            feat_indices_all=np.append(feat_indices_all,feat_indices)\n",
    "            feat_thresholds_all=np.append(feat_thresholds_all,feat_thresholds)\n",
    "            tree_indices_all=np.append(tree_indices_all,np.ones(n_ind)*tree_index)\n",
    "\n",
    "        indices_to_sort=np.argsort(feat_thresholds_all)\n",
    "        ordered_thresholds=feat_thresholds_all[indices_to_sort]\n",
    "        ordered_tree_indices=tree_indices_all[indices_to_sort]\n",
    "        ordered_indices=feat_indices_all[indices_to_sort]\n",
    "\n",
    "\n",
    "        for i in range(len(indices_to_sort)-1):\n",
    "            m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       <= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "            if ordered_thresholds[i]==ordered_thresholds[i+1]:\n",
    "                m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       >= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "\n",
    "    # Summing objective over all trees\n",
    "    m.setObjective(quicksum(quicksum(in_leaf_var[leaf,tree_index]*tree_in_forest.tree_.value[leaf,0,0] \n",
    "                                     for leaf in np.array(get_leaf_indices(tree_in_forest.tree_))) for tree_index,tree_in_forest in enumerate(estimators))/float(num_trees),GRB.MAXIMIZE)\n",
    "\n",
    "    m.write(\"new_model_file.lp\")\n",
    "    leaf_out=np.ones([num_trees])\n",
    "    if make_relax==True:\n",
    "        relax = m.relax()\n",
    "        relax.optimize()\n",
    "        obj = relax.getObjective()\n",
    "    else:\n",
    "        m.optimize()\n",
    "        obj = m.getObjective()\n",
    "        leaf_out=np.ones([num_trees])\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "            tree=tree_in_forest.tree_\n",
    "            index_leaves=np.array(get_leaf_indices(tree))\n",
    "            for i in index_leaves:\n",
    "                if m.getVarByName(\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index)).x==1:\n",
    "                    leaf_out[tree_index]=i\n",
    "                    \n",
    "\n",
    "        print('leaf_out',leaf_out)\n",
    "    \n",
    "    return obj.getValue(),leaf_out\n",
    "\n",
    "# bigM formulation\n",
    "def tighter_random_forest_IP_unconstrained(estimators,num_total_features,make_relax):\n",
    "\n",
    "    m = Model(\"RF\")\n",
    "    m.setParam('TimeLimit', 1800)\n",
    "    num_trees=len(estimators)\n",
    "\n",
    "    print(\"num_total_features\",num_total_features)\n",
    "\n",
    "    #initialize variables\n",
    "    in_leaf_var={}\n",
    "    split_var={}\n",
    "    feature_var={}\n",
    "    in_jury={}\n",
    "    tree_obj={}\n",
    "\n",
    "    for i in range(num_total_features):\n",
    "        feature_var[i]=m.addVar(name=\"feature_var\"+str(i))\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "        tree=tree_in_forest.tree_\n",
    "        num_nodes=tree.node_count\n",
    "        ## leaf nodes\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "        ## interior nodes\n",
    "        index_splits=np.where(tree.children_left!= (-1))[0]\n",
    "\n",
    "        # coming up with tight big M values\n",
    "        max_threshold=max(abs(tree.threshold))+1\n",
    "\n",
    "        # q^k_{i,r_i} and q^k_{i,l_i} in the model\n",
    "        for i in index_splits:\n",
    "            split_var[i,tree.children_left[i],tree_index]=m.addVar(vtype=GRB.BINARY,name=\"split_var\"+str(i)+str(tree.children_left[i])+\"tree_index\"+str(tree_index))\n",
    "            split_var[i,tree.children_right[i],tree_index]=m.addVar(vtype=GRB.BINARY,name=\"split_var\"+str(i)+str(tree.children_right[i])+\"tree_index\"+str(tree_index))\n",
    "        # z^k_j\n",
    "        for i in index_leaves:\n",
    "            in_leaf_var[i,tree_index]=m.addVar(vtype=GRB.BINARY,name=\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index))\n",
    "\n",
    "        tree_obj[tree_index]=m.addVar(name='tree_obj'+str(tree_index))\n",
    "\n",
    "        m.update()\n",
    "        ## adding objective sum_{j leaf} z^k_j S^k_j for a tree k\n",
    "        m.addConstr(tree_obj[tree_index]==quicksum(in_leaf_var[leaf,tree_index]*tree.value[leaf,0,0] for leaf in index_leaves))\n",
    "\n",
    "        # branching constraint\n",
    "        for split in index_splits:\n",
    "            #Big M constraints\n",
    "            m.addConstr(feature_var[tree.feature[split]]-max_threshold*(1-split_var[split,tree.children_left[split],tree_index]) <= tree.threshold[split] )\n",
    "            m.addConstr(feature_var[tree.feature[split]]+max_threshold*(1-split_var[split,tree.children_right[split],tree_index]) >= tree.threshold[split] )\n",
    "\n",
    "            left=tree.children_left[split]\n",
    "            if tree.children_left[split] in index_splits:\n",
    "                left_right=tree.children_right[left]\n",
    "                left_left=tree.children_left[left]\n",
    "                # We do not need the first two contraints\n",
    "                # equal flow in the interior node i\n",
    "                m.addConstr(split_var[split,left,tree_index] >= split_var[left,left_right,tree_index])\n",
    "                m.addConstr(split_var[split,left,tree_index] >= split_var[left,left_left,tree_index])\n",
    "                m.addConstr(split_var[split,left,tree_index] == split_var[left,left_right,tree_index]+split_var[left,left_left,tree_index])\n",
    "            else:\n",
    "                m.addConstr(split_var[split,left,tree_index] >= in_leaf_var[left,tree_index])\n",
    "\n",
    "            right=tree.children_right[split]\n",
    "            if tree.children_right[split] in index_splits:\n",
    "                right_right=tree.children_right[right]\n",
    "                right_left=tree.children_left[right]\n",
    "                m.addConstr(split_var[split,right,tree_index] == split_var[right,right_left,tree_index]+split_var[right,right_right,tree_index])\n",
    "                m.addConstr(split_var[split,right,tree_index] >= split_var[right,right_left,tree_index])\n",
    "                m.addConstr(split_var[split,right,tree_index] >= split_var[right,right_left,tree_index])\n",
    "            else:\n",
    "                m.addConstr(split_var[split,right,tree_index] >= in_leaf_var[right,tree_index])\n",
    "        # sum over z^k_j =1 for tree k\n",
    "        m.addConstr(quicksum(in_leaf_var[leaf,tree_index] for leaf in index_leaves)==1)\n",
    "    # Summing objective over all trees\n",
    "    m.setObjective(quicksum(tree_obj[tree_index] for tree_index,tree_in_forest in enumerate(estimators))/float(num_trees),GRB.MAXIMIZE)\n",
    "    m.write(\"unconst_model_file.lp\")\n",
    "    \n",
    "    feature_var_out=np.ones([num_total_features])\n",
    "    if make_relax==True:\n",
    "        relax = m.relax()\n",
    "        relax.optimize()\n",
    "        obj = relax.getObjective()\n",
    "    else:\n",
    "        m.optimize()\n",
    "        '''\n",
    "        #m.write(\"model_file.lp\")\n",
    "        m.computeIIS()\n",
    "        m.write(\"model.ilp\")\n",
    "        print(\"IIS written to file 'model.ilp'\")\n",
    "        print(\"STATUS\", m.Status)\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # output the results\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "            tree=tree_in_forest.tree_\n",
    "            index_leaves=np.where(tree.children_left== (-1))[0]\n",
    "            index_splits=np.where(tree.children_left!= (-1))[0]\n",
    "\n",
    "            #in_leaf=np.empty([num_leaves])\n",
    "            #print(\"index_leaves\",index_leaves)\n",
    "            for leaf in index_leaves:\n",
    "                print(m.getVarByName(\"in_leaf_var\"+str(leaf)+\"tree_index\"+str(tree_index)),\n",
    "                      m.getVarByName(\"in_leaf_var\"+str(leaf)+\"tree_index\"+str(tree_index)).x)\n",
    "                #in_leaf[leaf]=m.getVarByName(\"in_leaf_var\"+str(leaf)).x\n",
    "\n",
    "            #splits=np.empty([num_splits])\n",
    "            for split in index_splits:\n",
    "                print(m.getVarByName(\"split_var\"+str(split)+\"tree_index\"+str(tree_index)),\n",
    "                      m.getVarByName(\"split_var\"+str(split)+\"tree_index\"+str(tree_index)).x)\n",
    "                #splits[split]=m.getVarByName(\"split_var\"+str(split)).x\n",
    "        '''\n",
    "\n",
    "        for i in range(num_total_features):\n",
    "            feature_var_out[i]=m.getVarByName(\"feature_var\"+str(i)).x\n",
    "\n",
    "        print(\"feature_var_out\",feature_var_out)\n",
    "        obj = m.getObjective()\n",
    "        print(\"tight_formulation obj\",obj.getValue())\n",
    "\n",
    "\n",
    "    return feature_var_out,obj.getValue(), m.Runtime\n",
    "\n",
    "\n",
    "\n",
    "# elbow+expset formulation\n",
    "def misic_opt_tighter_with_cuts(estimators,num_total_features,feature_upper_bounds,feature_lower_bounds,x,eps,make_continuous,deviation_bound,make_relax):\n",
    "\n",
    "    m = Model(\"RF both ways greater and less than\")\n",
    "#     m.setParam('TimeLimit', 60)\n",
    "    m.setParam('TimeLimit', 1800)\n",
    "    num_trees=len(estimators)\n",
    "    in_leaf_var={}\n",
    "    split_var={}\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "        tree=tree_in_forest.tree_\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "\n",
    "        for leaf in index_leaves:\n",
    "            in_leaf_var[leaf,tree_index]=m.addVar(vtype=GRB.BINARY,name=\"in_leaf_var\"+str(leaf)+\"tree_index\"+str(tree_index))\n",
    "\n",
    "        m.addConstr(quicksum(in_leaf_var[leaf,tree_index] for leaf in index_leaves)==1)\n",
    "\n",
    "\n",
    "    for feat in range(n_feature):\n",
    "\n",
    "        print('feat',feat)\n",
    "\n",
    "        feat_indices_all=[]\n",
    "        tree_indices_all=[]\n",
    "        feat_thresholds_all=[]\n",
    "\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "            print('tree_index',tree_index)\n",
    "\n",
    "            tree=tree_in_forest.tree_\n",
    "            feat_indices=np.where(tree.feature==feat)[0]\n",
    "            feat_thresholds=tree.threshold[tree.feature==feat]\n",
    "            order_indices=np.argsort(feat_thresholds)\n",
    "\n",
    "            leaf_indices=set()\n",
    "            n_ind=len(feat_indices)\n",
    "\n",
    "            for i in range(n_ind):\n",
    "                split_var[feat,feat_indices[order_indices][i],tree_index]=m.addVar(vtype=GRB.BINARY,name=\"split_var\"+str(feat)+\"-\"+str(feat_indices[order_indices][i])+\"_tree\"+str(tree_index))\n",
    "\n",
    "                new_leaf_indices=get_leaf_indices_recursive(tree,tree.children_left[feat_indices[order_indices][i]])\n",
    "                leaf_indices= new_leaf_indices | leaf_indices\n",
    "                m.addConstr(split_var[feat,feat_indices[order_indices][i],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in leaf_indices))\n",
    "\n",
    "                # find parent, check if same feature, then add\n",
    "                current_index=feat_indices[order_indices][i]\n",
    "                parent_index= np.where(tree.children_right == current_index)[0]\n",
    "                if tree.feature[parent_index]== feat:\n",
    "                    m.addConstr(split_var[feat,current_index,tree_index]-split_var[feat,parent_index[0],tree_index] >= \n",
    "                                quicksum(in_leaf_var[leaf,tree_index] for leaf in new_leaf_indices))\n",
    "\n",
    "            larger_leaf_indices=set()\n",
    "\n",
    "            for i in range(n_ind):\n",
    "                right_leaf_indices=get_leaf_indices_recursive(tree,tree.children_right[feat_indices[order_indices][n_ind-i-1]])\n",
    "                larger_leaf_indices= right_leaf_indices | larger_leaf_indices\n",
    "                m.addConstr(1 - split_var[feat,feat_indices[order_indices][n_ind-i-1],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in larger_leaf_indices))\n",
    "\n",
    "                #find parent, check if same feature, then add\n",
    "                current_index=feat_indices[order_indices][n_ind-i-1]\n",
    "                parent_index= np.where(tree.children_left == current_index)[0]\n",
    "                if tree.feature[parent_index]== feat:\n",
    "                    m.addConstr(split_var[feat,parent_index[0],tree_index]-split_var[feat,current_index,tree_index] >= \n",
    "                                quicksum(in_leaf_var[leaf,tree_index] for leaf in right_leaf_indices))\n",
    "\n",
    "            feat_indices_all=np.append(feat_indices_all,feat_indices)\n",
    "            feat_thresholds_all=np.append(feat_thresholds_all,feat_thresholds)\n",
    "            tree_indices_all=np.append(tree_indices_all,np.ones(n_ind)*tree_index)\n",
    "\n",
    "        indices_to_sort=np.argsort(feat_thresholds_all)\n",
    "        ordered_thresholds=feat_thresholds_all[indices_to_sort]\n",
    "        ordered_tree_indices=tree_indices_all[indices_to_sort]\n",
    "        ordered_indices=feat_indices_all[indices_to_sort]\n",
    "\n",
    "        tree.children_left\n",
    "\n",
    "        for i in range(len(indices_to_sort)-1):\n",
    "            m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       <= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "            if ordered_thresholds[i]==ordered_thresholds[i+1]:\n",
    "                m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       >= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "\n",
    "    # Summing objective over all trees\n",
    "    m.setObjective(quicksum(quicksum(in_leaf_var[leaf,tree_index]*tree_in_forest.tree_.value[leaf,0,0] \n",
    "                                     for leaf in np.array(get_leaf_indices(tree_in_forest.tree_))) for tree_index,tree_in_forest in enumerate(estimators))/float(num_trees),GRB.MAXIMIZE)\n",
    "\n",
    "    m.write(\"new_model_file.lp\")\n",
    "    leaf_out=np.ones([num_trees])\n",
    "    if make_relax==True:\n",
    "        relax = m.relax()\n",
    "        relax.optimize()\n",
    "        obj = relax.getObjective()\n",
    "    else:\n",
    "        m.optimize()\n",
    "        obj = m.getObjective()\n",
    "        leaf_out=np.ones([num_trees])\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "            tree=tree_in_forest.tree_\n",
    "            index_leaves=np.array(get_leaf_indices(tree))\n",
    "            for i in index_leaves:\n",
    "                if m.getVarByName(\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index)).x==1:\n",
    "                    leaf_out[tree_index]=i\n",
    "    \n",
    "    return obj.getValue(),leaf_out\n",
    "\n",
    "\n",
    "# elbow formulation\n",
    "def misic_opt_tighter_with_cuts_2(estimators,num_total_features,feature_upper_bounds,feature_lower_bounds,x,eps,make_continuous,deviation_bound,make_relax):\n",
    "\n",
    "    m = Model(\"RF both ways greater and less than\")\n",
    "#     m.setParam('TimeLimit', 1800)\n",
    "    m.setParam('TimeLimit', 60)\n",
    "    num_trees=len(estimators)\n",
    "    in_leaf_var={}\n",
    "    split_var={}\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "        tree=tree_in_forest.tree_\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "\n",
    "        for leaf in index_leaves:\n",
    "            in_leaf_var[leaf,tree_index]=m.addVar(vtype=GRB.BINARY,name=\"in_leaf_var\"+str(leaf)+\"tree_index\"+str(tree_index))\n",
    "\n",
    "        m.addConstr(quicksum(in_leaf_var[leaf,tree_index] for leaf in index_leaves)==1)\n",
    "\n",
    "\n",
    "    for feat in range(n_feature):\n",
    "\n",
    "        print('feat',feat)\n",
    "\n",
    "        feat_indices_all=[]\n",
    "        tree_indices_all=[]\n",
    "        feat_thresholds_all=[]\n",
    "\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "            print('tree_index',tree_index)\n",
    "\n",
    "            tree=tree_in_forest.tree_\n",
    "            feat_indices=np.where(tree.feature==feat)[0]\n",
    "            feat_thresholds=tree.threshold[tree.feature==feat]\n",
    "            order_indices=np.argsort(feat_thresholds)\n",
    "\n",
    "            leaf_indices=set()\n",
    "            n_ind=len(feat_indices)\n",
    "\n",
    "            for i in range(n_ind):\n",
    "                split_var[feat,feat_indices[order_indices][i],tree_index]=m.addVar(vtype=GRB.BINARY,name=\"split_var\"+str(feat)+\"-\"+str(feat_indices[order_indices][i])+\"_tree\"+str(tree_index))\n",
    "\n",
    "                new_leaf_indices=get_leaf_indices_recursive(tree,tree.children_left[feat_indices[order_indices][i]])\n",
    "                m.addConstr(split_var[feat,feat_indices[order_indices][i],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in new_leaf_indices))\n",
    "\n",
    "                # find parent, check if same feature, then add\n",
    "                current_index=feat_indices[order_indices][i]\n",
    "                parent_index= np.where(tree.children_right == current_index)[0]\n",
    "                if tree.feature[parent_index]== feat:\n",
    "                    m.addConstr(split_var[feat,current_index,tree_index]-split_var[feat,parent_index[0],tree_index] >= \n",
    "                                quicksum(in_leaf_var[leaf,tree_index] for leaf in new_leaf_indices))\n",
    "\n",
    "            larger_leaf_indices=set()\n",
    "\n",
    "            for i in range(n_ind):\n",
    "                right_leaf_indices=get_leaf_indices_recursive(tree,tree.children_right[feat_indices[order_indices][n_ind-i-1]])\n",
    "                m.addConstr(1 - split_var[feat,feat_indices[order_indices][n_ind-i-1],tree_index] >= quicksum(in_leaf_var[leaf,tree_index] for leaf in right_leaf_indices))\n",
    "\n",
    "                #find parent, check if same feature, then add\n",
    "                current_index=feat_indices[order_indices][n_ind-i-1]\n",
    "                parent_index= np.where(tree.children_left == current_index)[0]\n",
    "                if tree.feature[parent_index]== feat:\n",
    "                    m.addConstr(split_var[feat,parent_index[0],tree_index]-split_var[feat,current_index,tree_index] >= \n",
    "                                quicksum(in_leaf_var[leaf,tree_index] for leaf in right_leaf_indices))\n",
    "\n",
    "            feat_indices_all=np.append(feat_indices_all,feat_indices)\n",
    "            feat_thresholds_all=np.append(feat_thresholds_all,feat_thresholds)\n",
    "            tree_indices_all=np.append(tree_indices_all,np.ones(n_ind)*tree_index)\n",
    "\n",
    "        indices_to_sort=np.argsort(feat_thresholds_all)\n",
    "        ordered_thresholds=feat_thresholds_all[indices_to_sort]\n",
    "        ordered_tree_indices=tree_indices_all[indices_to_sort]\n",
    "        ordered_indices=feat_indices_all[indices_to_sort]\n",
    "\n",
    "        tree.children_left\n",
    "\n",
    "        for i in range(len(indices_to_sort)-1):\n",
    "            m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       <= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "            if ordered_thresholds[i]==ordered_thresholds[i+1]:\n",
    "                m.addConstr(split_var[feat,ordered_indices[i],ordered_tree_indices[i]] \n",
    "                       >= split_var[feat,ordered_indices[i+1],ordered_tree_indices[i+1]])\n",
    "\n",
    "    # Summing objective over all trees\n",
    "    m.setObjective(quicksum(quicksum(in_leaf_var[leaf,tree_index]*tree_in_forest.tree_.value[leaf,0,0] \n",
    "                                     for leaf in np.array(get_leaf_indices(tree_in_forest.tree_))) for tree_index,tree_in_forest in enumerate(estimators))/float(num_trees),GRB.MAXIMIZE)\n",
    "\n",
    "    m.write(\"new_model_file.lp\")\n",
    "    leaf_out=np.ones([num_trees])\n",
    "    if make_relax==True:\n",
    "        relax = m.relax()\n",
    "        relax.optimize()\n",
    "        obj = relax.getObjective()\n",
    "    else:\n",
    "        m.optimize()\n",
    "        obj = m.getObjective()\n",
    "        leaf_out=np.ones([num_trees])\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "            tree=tree_in_forest.tree_\n",
    "            index_leaves=np.array(get_leaf_indices(tree))\n",
    "            for i in index_leaves:\n",
    "                if m.getVarByName(\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index)).x==1:\n",
    "                    leaf_out[tree_index]=i\n",
    "    \n",
    "    return obj.getValue(),leaf_out, m.Runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_continuous_variable_new(estimators,m,split_var,splits,num_total_features,feature_lower_bounds,feature_upper_bounds,eps):\n",
    "    \n",
    "    feature_var={}\n",
    "    for i in range(num_total_features):\n",
    "        feature_var[i]=m.addVar(lb=-GRB.INFINITY,name=\"feature_var\"+str(i))\n",
    "        \n",
    "    m.update()\n",
    "\n",
    "    for feat in range(num_total_features):\n",
    "        if len(splits[feat])>0:\n",
    "            const_expr_UB=[split_var[feat,split_ind]*(splits[feat][split_ind]-splits[feat][split_ind+1]) \n",
    "            for  split_ind,split_value in enumerate(splits[feat]) if split_ind < len(splits[feat])-1]+[feature_upper_bounds[feat]+ (splits[feat][len(splits[feat])-1]-feature_upper_bounds[feat])*split_var[feat,len(splits[feat])-1]]\n",
    "\n",
    "            const_expr_LB=[split_var[feat,split_ind]*(splits[feat][split_ind-1]-splits[feat][split_ind]) \n",
    "            for  split_ind,split_value in enumerate(splits[feat]) if split_ind > 0]+[splits[feat][len(splits[feat])-1]+ (feature_lower_bounds[feat]-splits[feat][0])*split_var[feat,0]]\n",
    "            m.addConstr(feature_var[feat]<= quicksum(const_expr_UB)-eps)\n",
    "            m.addConstr(feature_var[feat]>= quicksum(const_expr_LB)+eps)\n",
    "        else:\n",
    "            m.addConstr(feature_var[feat]<= feature_upper_bounds[feat])\n",
    "            m.addConstr(feature_var[feat]>= feature_lower_bounds[feat])\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    return feature_var,m\n",
    "\n",
    "# projected formulation\n",
    "def projected_extended_random_forest_IP_unconstrained(estimators,num_total_features,feature_upper_bounds,feature_lower_bounds,x,eps,deviation_bound=False,make_relax=False):\n",
    "\n",
    "    m = Model(\"RF\")\n",
    "    m.setParam('TimeLimit', 1800)\n",
    "#     m.setParam('TimeLimit', 60)\n",
    "    num_trees=len(estimators)\n",
    "\n",
    "    print(\"num_total_features\",num_total_features)\n",
    "\n",
    "    #initialise variables\n",
    "    in_leaf_var={}\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "        tree=tree_in_forest.tree_\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "        for leaf in index_leaves:\n",
    "            in_leaf_var[leaf,tree_index]=m.addVar(vtype=GRB.BINARY,name=\"in_leaf_var\"+str(leaf)+\"tree_index\"+str(tree_index))\n",
    "\n",
    "        m.addConstr(quicksum(in_leaf_var[leaf,tree_index] for leaf in index_leaves)==1)\n",
    "    \n",
    "    feature_var,m=make_continuous_variable(estimators,m,in_leaf_var,num_total_features,eps)\n",
    "    m.update()\n",
    "    \n",
    "    if deviation_bound==True:\n",
    "        m=add_deviation_bound(m,feature_var,x,num_total_features)\n",
    "    \n",
    "    # Summing objective over all trees\n",
    "    m.setObjective(quicksum(quicksum(in_leaf_var[leaf,tree_index]*tree_in_forest.tree_.value[leaf,0,0] for leaf in np.array(get_leaf_indices(tree_in_forest.tree_))) for tree_index,tree_in_forest in enumerate(estimators))/float(num_trees),GRB.MAXIMIZE)\n",
    "    m.write(\"extended_model_file.lp\")\n",
    "    \n",
    "    leaf_out=np.ones([num_trees])\n",
    "    feature_var_out=np.ones([num_total_features])\n",
    "\n",
    "    if make_relax==True:\n",
    "        relax = m.relax()\n",
    "        relax.optimize()\n",
    "        obj = relax.getObjective()\n",
    "    else:\n",
    "        m.optimize()\n",
    "\n",
    "        for i in range(num_total_features):\n",
    "            feature_var_out[i]=m.getVarByName(\"feature_var\"+str(i)).x\n",
    "\n",
    "        print(\"feature_var_out\",feature_var_out)\n",
    "        obj = m.getObjective()\n",
    "        print(\"tight_formulation obj\",obj.getValue())\n",
    "\n",
    "        for tree_index,tree_in_forest in enumerate(estimators):\n",
    "            tree=tree_in_forest.tree_\n",
    "            index_leaves=np.array(get_leaf_indices(tree))\n",
    "            for i in index_leaves:\n",
    "                if m.getVarByName(\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index)).x==1:\n",
    "                    leaf_out[tree_index]=i\n",
    "\n",
    "    return feature_var_out,obj.getValue(),leaf_out, m.Runtime\n",
    "\n",
    "\n",
    "def misic_rf_unconstrained(estimators,num_total_features,feature_upper_bounds,feature_lower_bounds,x,eps,make_continuous,deviation_bound):\n",
    "\n",
    "    m = Model(\"RF\")\n",
    "    m.setParam('TimeLimit', 1800)\n",
    "    m.setParam('TimeLimit', 60)\n",
    "    num_trees=len(estimators)\n",
    "\n",
    "    print(\"num_total_features\",num_total_features)\n",
    "\n",
    "    #initialise variables\n",
    "    in_leaf_var={}\n",
    "    split_var={}\n",
    "    tree_obj={}\n",
    "\n",
    "    # get 2D list of splits\n",
    "    splits=get_ordered_thresholds_for_each_feature(estimators, num_total_features)\n",
    "\n",
    "    for feat in range(num_total_features):\n",
    "        for split_ind,split_value in enumerate(splits[feat]):\n",
    "            split_var[feat,split_ind]=m.addVar(vtype=GRB.BINARY,name=\"split_var\"+str(feat)+\"-\"+str(split_ind))\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "        tree=tree_in_forest.tree_\n",
    "        num_nodes=tree.node_count\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "        ## interior nodes\n",
    "        index_splits=np.where(tree.children_left!= (-1))[0]\n",
    "\n",
    "        for i in index_leaves:\n",
    "            in_leaf_var[i,tree_index]=m.addVar(name=\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index))\n",
    "\n",
    "        tree_obj[tree_index]=m.addVar(name='tree_obj'+str(tree_index))\n",
    "\n",
    "        m.update()\n",
    "        m.addConstr(tree_obj[tree_index]==quicksum(in_leaf_var[leaf,tree_index]*tree.value[leaf,0,0] for leaf in index_leaves))\n",
    "        binary_path=get_binary_path_to_leaf(np.ones(num_nodes)*(-1),tree,0)\n",
    "\n",
    "        # branching constraint\n",
    "        for split in index_splits:\n",
    "            left_descendents=[]\n",
    "            right_descendents=[]\n",
    "\n",
    "            if tree.children_left[split] in index_leaves:\n",
    "                left_descendents.append(tree.children_left[split])\n",
    "\n",
    "            if tree.children_right[split] in index_leaves:\n",
    "                right_descendents.append(tree.children_right[split])\n",
    "\n",
    "            for leaf in index_leaves:\n",
    "                # check if this leaf is a descendent of this split\n",
    "                if not(binary_path[leaf][tree.children_left[split]] == -1):\n",
    "                    left_descendents.append(leaf)\n",
    "                if not(binary_path[leaf][tree.children_right[split]] == -1):\n",
    "                    right_descendents.append(leaf)\n",
    "\n",
    "            #find corresp thresh\n",
    "            split_pos=splits[tree.feature[split]].index(tree.threshold[split])\n",
    "\n",
    "            m.addConstr(quicksum(in_leaf_var[desc,tree_index] for desc in left_descendents)<= split_var[tree.feature[split],split_pos])\n",
    "            m.addConstr(quicksum(in_leaf_var[desc,tree_index] for desc in right_descendents)<= 1-split_var[tree.feature[split],split_pos])\n",
    "\n",
    "        m.addConstr(quicksum(in_leaf_var[leaf,tree_index] for leaf in index_leaves)==1)\n",
    "\n",
    "    for feat in range(num_total_features):\n",
    "        for split_ind,split_value in enumerate(splits[feat]):\n",
    "            if split_ind<len(splits[feat])-1:\n",
    "                m.addConstr(split_var[feat,split_ind] <=split_var[feat,split_ind+1])\n",
    "                \n",
    "    if make_continuous==True: \n",
    "        feature_var,m=make_continuous_variable_new(estimators,m,split_var,splits,num_total_features,feature_lower_bounds,feature_upper_bounds,eps)\n",
    "        m.update()\n",
    "        if deviation_bound==True:\n",
    "            m=add_deviation_bound(m,feature_var,x,num_total_features)\n",
    "            \n",
    "        \n",
    "    m.update()   \n",
    "\n",
    "    # Summing objective over all trees\n",
    "    m.setObjective(quicksum(tree_obj[tree_index] for tree_index,tree_in_forest in enumerate(estimators))/float(num_trees),GRB.MAXIMIZE)\n",
    "    m.write(\"unconst_model_file.lp\")\n",
    "    m.optimize()\n",
    "    obj = m.getObjective()\n",
    "\n",
    "    if make_continuous==True: \n",
    "        print(\"in loop\")\n",
    "        feature_var_out=np.ones([num_total_features])\n",
    "        for i in range(num_total_features):\n",
    "            feature_var_out[i]=m.getVarByName(\"feature_var\"+str(i)).x\n",
    "    else:\n",
    "        feature_var_out=np.ones([num_total_features])\n",
    "        for feat in range(num_total_features):\n",
    "            if len(splits[feat])>0:\n",
    "                feature_var_out[feat]=max(splits[feat])+eps\n",
    "                chosen_split=max(splits[feat])\n",
    "                for split_ind,split_value in enumerate(splits[feat]):\n",
    "                    var_sol=m.getVarByName(\"split_var\"+str(feat)+\"-\"+str(split_ind)).x\n",
    "                    if var_sol==1:\n",
    "                        if split_value < chosen_split:\n",
    "                            feature_var_out[feat]=split_value-eps\n",
    "                            chosen_split=split_value\n",
    "\n",
    "                    \n",
    "    leaf_out=np.ones([num_trees])\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "        tree=tree_in_forest.tree_\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "        for i in index_leaves:\n",
    "            if m.getVarByName(\"in_leaf_var\"+str(i)+\"tree_index\"+str(tree_index)).x==1:\n",
    "                leaf_out[tree_index]=i\n",
    "                \n",
    "\n",
    "    print('feature_var_out',feature_var_out)\n",
    "    print('obj.getValue()',obj.getValue())\n",
    "    return feature_var_out, obj.getValue(),leaf_out\n",
    "\n",
    "\n",
    "def make_continuous_variable(estimators,m,in_leaf_var,num_total_features,eps):\n",
    "    \n",
    "    feature_var={}\n",
    "    #The variable x_i in the model\n",
    "    for i in range(num_total_features):\n",
    "        feature_var[i]=m.addVar(lb=-GRB.INFINITY,name=\"feature_var\"+str(i))\n",
    "\n",
    "    for tree_index,tree_in_forest in enumerate(estimators):\n",
    "\n",
    "        tree=tree_in_forest.tree_\n",
    "        num_nodes=tree.node_count\n",
    "        ## leaf nodes\n",
    "        index_leaves=np.array(get_leaf_indices(tree))\n",
    "        n_leaves=index_leaves.size\n",
    "\n",
    "        # 0 for left, 1 for right to all leaves in a dictionary\n",
    "        binary_path=get_binary_path_to_leaf(np.ones(num_nodes)*(-1),tree,0)\n",
    "\n",
    "        m.update()\n",
    "\n",
    "        # demand constraint\n",
    "        upper_bound_leaf=np.ones([num_nodes,num_total_features])\n",
    "        lower_bound_leaf=np.ones([num_nodes,num_total_features])\n",
    "\n",
    "        for leaf in index_leaves:\n",
    "\n",
    "            index_right=np.where(binary_path[leaf]==1)[0]\n",
    "            index_left=np.where(binary_path[leaf]==0)[0]\n",
    "            upper_threshold=tree.threshold[index_left]\n",
    "            lower_threshold=tree.threshold[index_right]\n",
    "            feature_split_left=tree.feature[index_left]\n",
    "            feature_split_right=tree.feature[index_right]\n",
    "\n",
    "            for feat in range(num_total_features):\n",
    "                if feat in feature_split_left:\n",
    "                    split_loc=np.where(feature_split_left==feat)[0]\n",
    "                    upper_bound_leaf[leaf,feat]=min(upper_threshold[split_loc])\n",
    "                else: upper_bound_leaf[leaf,feat] = feature_upper_bounds[feat]\n",
    "\n",
    "                if feat in feature_split_right:\n",
    "                    split_loc=np.where(feature_split_right==feat)[0]\n",
    "                    lower_bound_leaf[leaf,feat]=max(lower_threshold[split_loc])\n",
    "                else: lower_bound_leaf[leaf,feat] = feature_lower_bounds[feat]\n",
    "\n",
    "\n",
    "        for feat in range(num_total_features):\n",
    "            m.addConstr(feature_var[feat]>=eps+quicksum(in_leaf_var[leaf,tree_index]*lower_bound_leaf[leaf,feat] for leaf in index_leaves))\n",
    "            m.addConstr(feature_var[feat]+eps<=quicksum(in_leaf_var[leaf,tree_index]*upper_bound_leaf[leaf,feat] for leaf in index_leaves))\n",
    "    m.update()\n",
    "    return feature_var,m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def line(error_y_mode=None, **kwargs):\n",
    "    \"\"\"Extension of `plotly.express.line` to use error bands.\"\"\"\n",
    "    ERROR_MODES = {'bar','band','bars','bands',None}\n",
    "    if error_y_mode not in ERROR_MODES:\n",
    "        raise ValueError(f\"'error_y_mode' must be one of {ERROR_MODES}, received {repr(error_y_mode)}.\")\n",
    "    if error_y_mode in {'bar','bars',None}:\n",
    "        fig = px.line(**kwargs)\n",
    "    elif error_y_mode in {'band','bands'}:\n",
    "        if 'error_y' not in kwargs:\n",
    "            raise ValueError(f\"If you provide argument 'error_y_mode' you must also provide 'error_y'.\")\n",
    "        figure_with_error_bars = px.line(**kwargs)\n",
    "        fig = px.line(**{arg: val for arg,val in kwargs.items() if arg != 'error_y'})\n",
    "        for data in figure_with_error_bars.data:\n",
    "            x = list(data['x'])\n",
    "            y_upper = list(data['y'] + data['error_y']['array'])\n",
    "            y_lower = list(data['y'] - data['error_y']['array'] if data['error_y']['arrayminus'] is None else data['y'] - data['error_y']['arrayminus'])\n",
    "            color = f\"rgba({tuple(int(data['line']['color'].lstrip('#')[i:i+2], 16) for i in (0, 2, 4))},.1)\".replace('((','(').replace('),',',').replace(' ','')\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x = x+x[::-1],\n",
    "                    y = y_upper+y_lower[::-1],\n",
    "                    fill = 'toself',\n",
    "                    fillcolor = color,\n",
    "                    line = dict(\n",
    "                        color = 'rgba(255,255,255,0)'\n",
    "                    ),\n",
    "                    hoverinfo = \"skip\",\n",
    "                    showlegend = False,\n",
    "                    legendgroup = data['legendgroup'],\n",
    "                    xaxis = data['xaxis'],\n",
    "                    yaxis = data['yaxis'],\n",
    "                )\n",
    "            )\n",
    "        # Reorder data as said here: https://stackoverflow.com/a/66854398/8849755\n",
    "        reordered_data = []\n",
    "        for i in range(int(len(fig.data)/2)):\n",
    "            reordered_data.append(fig.data[i+int(len(fig.data)/2)])\n",
    "            reordered_data.append(fig.data[i])\n",
    "        fig.data = tuple(reordered_data)\n",
    "\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
